<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rahul Vigneswaran</title>
    <link>/authors/admin/</link>
      <atom:link href="/authors/admin/index.xml" rel="self" type="application/rss+xml" />
    <description>Rahul Vigneswaran</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2021 Rahul Vigneswaran Â©</copyright><lastBuildDate>Mon, 11 Oct 2021 07:56:52 +0530</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:square]</url>
      <title>Rahul Vigneswaran</title>
      <link>/authors/admin/</link>
    </image>
    
    <item>
      <title>Long Tail Classification ðŸ“‰</title>
      <link>/post/long-tail-classification/</link>
      <pubDate>Mon, 11 Oct 2021 07:56:52 +0530</pubDate>
      <guid>/post/long-tail-classification/</guid>
      <description>&lt;!-- Template

&lt;!-- #### []() 
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Datasets&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CIFAR-LT 100&lt;/li&gt;
&lt;li&gt;ImageNet-LT&lt;/li&gt;
&lt;li&gt;Places-LT&lt;/li&gt;
&lt;li&gt;iNaturalist18&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;


##### Summary --&gt;
&lt;!-- #### []() 
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Experimental Setup&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Dataset&lt;/th&gt;
&lt;th&gt;Architecture&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CIFAR-LT 100&lt;/td&gt;
&lt;td&gt;ResNet-32&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ImageNet-LT&lt;/td&gt;
&lt;td&gt;ResNeXt-50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Places-LT&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;iNaturalist18&lt;/td&gt;
&lt;td&gt;ResNeXt-50&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
  &lt;/div&gt;
&lt;/div&gt;


##### Summary --&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    Updates&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Oct 21] Started adding CVPR, ICLR 21 papers.&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#2021&#34;&gt;2021&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#cvpr-21&#34;&gt;CVPR 21&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;

&lt;h2 id=&#34;2021&#34;&gt;2021&lt;/h2&gt;
&lt;h3 id=&#34;cvpr-21&#34;&gt;CVPR 21&lt;/h3&gt;
&lt;h4 id=&#34;improving-calibration-for-long-tailed-recognitionhttpsarxivorgpdf210400466pdf&#34;&gt;
&lt;a href=&#34;https://arxiv.org/pdf/2104.00466.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Improving Calibration for Long-Tailed Recognition&lt;/a&gt;&lt;/h4&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Datasets&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CIFAR-LT 10/100&lt;/li&gt;
&lt;li&gt;ImageNet-LT&lt;/li&gt;
&lt;li&gt;Places-LT&lt;/li&gt;
&lt;li&gt;iNaturalist18&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h5 id=&#34;summary&#34;&gt;Summary&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;High Expected Calibration Error (ECE) for networks trained on LT datasets
&lt;ul&gt;
&lt;li&gt;Mix-up &lt;em&gt;(Takes care of CNN)&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;Mixup in 1st stage of decouple helps&lt;/li&gt;
&lt;li&gt;Reduces the weight norm of head and increases tail class weight norm
&lt;ul&gt;
&lt;li&gt;&lt;img src=&#34;2021-11-11-23-56-26.png&#34; alt=&#34;&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Label aware smoothing &lt;em&gt;(Takes care of Classifier)&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;Higher smoothing factor for head and lower for tail
&lt;ul&gt;
&lt;li&gt;They try three types - Concave, Linear, Convex
&lt;ul&gt;
&lt;li&gt;&lt;img src=&#34;2021-11-11-23-57-45.png&#34; alt=&#34;&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cRT has better representation ability and LWS has better generalization property
&lt;ul&gt;
&lt;li&gt;They combine both together in the second stage&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;2021-11-12-00-04-54.png&#34; alt=&#34;&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(Problem)&lt;/strong&gt; Dataset bias/domain shift when decoupling
&lt;ul&gt;
&lt;li&gt;In 2-stage training, stage-1 is trained on a different domain (sampler) than stage-2 -&amp;gt; Domain shift.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(Solution)&lt;/strong&gt; Batch Normalization
&lt;ul&gt;
&lt;li&gt;During stage 2, update the running mean and variance but donâ€™t change the trainable params in BN layer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Notes:
&lt;ul&gt;
&lt;li&gt;cRT: &lt;img src=&#34;2021-11-12-00-11-28.png&#34; alt=&#34;&#34;&gt;&lt;/li&gt;
&lt;li&gt;LWS&lt;img src=&#34;2021-11-12-00-12-37.png&#34; alt=&#34;&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Works better for large scale datasets compared to cRT.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;contrastive-learning-based-hybrid-networks-for-long-tailed-image-classificationhttpsarxivorgabs210314267&#34;&gt;
&lt;a href=&#34;https://arxiv.org/abs/2103.14267&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Contrastive Learning based Hybrid Networks for Long-Tailed Image Classification&lt;/a&gt;&lt;/h4&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Experimental Setup&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Dataset&lt;/th&gt;
&lt;th&gt;Architecture&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CIFAR-LT 10/100&lt;/td&gt;
&lt;td&gt;ResNet-32&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;iNaturalist18&lt;/td&gt;
&lt;td&gt;ResNet-50&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h5 id=&#34;summary-1&#34;&gt;Summary&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Main strategy:
&lt;ul&gt;
&lt;li&gt;Pull similar samples together AND Push dissimilar samples apart (Supervised contrastive learning (SC))&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hybrid network (Transition from 1 -&amp;gt; 2 with a curriculum) (!! Is this not similar to BBN? Yes but with two different loss instead of samplers) &lt;img src=&#34;2021-11-12-00-42-30.png&#34; alt=&#34;&#34;&gt;
&lt;ol&gt;
&lt;li&gt;Features -&amp;gt; Constrastive Loss  (SC)
&lt;ul&gt;
&lt;li&gt;Input : Labels are either positive or negative.&lt;/li&gt;
&lt;li&gt;Backbone : Common ResNet&lt;/li&gt;
&lt;li&gt;Projection head : Non-linear embedding layer (with 1 hidden layer) -&amp;gt; $l_2$ normalize the embedding&lt;/li&gt;
&lt;li&gt;Loss : Supervised contrastive learning loss ($L_{SCL}$)
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(Problem)&lt;/strong&gt; Extra memory consumption problem : We need to use both distance to the +ves and -ves. The number -ves would be high which makes it essential to keep alot of information in the memory.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(Solution)&lt;/strong&gt; Propose Prototypical supervised constrastive learning (PSC)
&lt;ul&gt;
&lt;li&gt;Pull towards prototypes of its own class and push away from the prototypes of all other classes.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multiple Prototype Contrastive Learning&lt;/strong&gt; (MPSC): While PSC uses only one prototype per class. (BUT THEY DONT SHOW ANY RESULTS ON THIS! Future work.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Classifier -&amp;gt; Cross-entropy  (CE)
&lt;ul&gt;
&lt;li&gt;Input: Usual labels&lt;/li&gt;
&lt;li&gt;Backbone : Common ResNet&lt;/li&gt;
&lt;li&gt;Projection head : Linear embedding layer (no hidden layer)&lt;/li&gt;
&lt;li&gt;Loss : Cross Entropy ($L_{CE}$)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!--     
#### [Disentangling Label Distribution for Long-tailed Visual Recognition [LADE]](https://arxiv.org/abs/2012.00321)

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Datasets&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CIFAR-LT 100&lt;/li&gt;
&lt;li&gt;ImageNet-LT&lt;/li&gt;
&lt;li&gt;Places-LT&lt;/li&gt;
&lt;li&gt;iNaturalist18&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;


##### Summary
- Consider it as label shift problem - Unmatched source and target label distribution
  - Disentangle source label distro and model prediction
    - After training [PC Softmax]: Baseline - Match model prediction to target label distro post-hoc
      - Post-Compensated (PC) Softmax
    - During training [LADE]: Disentangle model prediction and source label distro 
      - LADER loss disentangles logits from source label distro
      - Use LADE-CE loss to match logits to target label distro
      - LADE = LADE-CE + LADER



#### [Distribution Alignment: A Unified Framework for Long-tail Visual Recognition](https://arxiv.org/abs/2103.16370) 
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Experimental Setup&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Task&lt;/th&gt;
&lt;th&gt;Dataset&lt;/th&gt;
&lt;th&gt;Architecture&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Classification&lt;/td&gt;
&lt;td&gt;ImageNet-LT&lt;/td&gt;
&lt;td&gt;ResNet or ResNeXt-{50,101,152}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Classification&lt;/td&gt;
&lt;td&gt;Places-LT&lt;/td&gt;
&lt;td&gt;ResNet-{50,101,152}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Classification&lt;/td&gt;
&lt;td&gt;iNaturalist18&lt;/td&gt;
&lt;td&gt;ResNet-{50,101,152}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Object detection, Instance segmentation&lt;/td&gt;
&lt;td&gt;LVIS&lt;/td&gt;
&lt;td&gt;[ResNet-{50} AND Mask R-CNN+FPN] OR [[ResNet-{50,101} or ResNeXt-{101}] AND Cascade R-CNN]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Semantic segmentation&lt;/td&gt;
&lt;td&gt;ADE20k&lt;/td&gt;
&lt;td&gt;[ResNet-{50,101} OR ResNeSt-{101}]  AND [FCN OR DeepLabV3+]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
  &lt;/div&gt;
&lt;/div&gt;

##### Summary
- 

### ICLR 21
#### [RIDE: Long-tailed Recognition by Routing Diverse Distribution-Aware Experts](https://openreview.net/forum?id=D9I3drBz4UC) 
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Datasets&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CIFAR-LT 100&lt;/li&gt;
&lt;li&gt;ImageNet-LT&lt;/li&gt;
&lt;li&gt;iNaturalist18&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;


##### Summary
- Multiple experts - Reduces model variance
  - Use multiple experts (networks) with shared earlier layers
- Distribution aware diversity loss - Reduces model bias
  - Loss term that maximizes KL-div between experts
- Dynamic expert routing - Reduces computational cost
  - Instead of using all the experts, choose experts depending on the sample at hand
  - Self-distillation
      - Can also do self distillation from a model with more experts to fewer experts --&gt;
</description>
    </item>
    
    <item>
      <title>Tips &amp; Tricks: Working With Large Datasets ðŸ”¢</title>
      <link>/post/working-with-large-datasets-tips-tricks/</link>
      <pubDate>Mon, 11 Oct 2021 00:06:15 +0530</pubDate>
      <guid>/post/working-with-large-datasets-tips-tricks/</guid>
      <description>&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#gpu&#34;&gt;GPU&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#cpu&#34;&gt;CPU&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#storage&#34;&gt;Storage&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#general-training&#34;&gt;General Training&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#loss&#34;&gt;Loss&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#datasetdataloader&#34;&gt;Dataset/Dataloader&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#misc&#34;&gt;Misc&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;

&lt;h2 id=&#34;gpu&#34;&gt;GPU&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;If you have limited GPU memory, always lazy load the data. Instead of loading the images of the entire dataset at the same time, load the images batch by batch.
&lt;ul&gt;
&lt;li&gt;Check 
&lt;a href=&#34;https://discuss.pytorch.org/t/loading-huge-data-functionality/346/3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this thread&lt;/a&gt; for an example.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Batch size plays an important role in your training, so if you have a limited GPU memory and can&amp;rsquo;t fit the entire batch in it, do gradient accumulation. In this you do &lt;code&gt;optimizer.step&lt;/code&gt; and &lt;code&gt;model.zero_grad()&lt;/code&gt; once in few steps.
&lt;ul&gt;
&lt;li&gt;Check 
&lt;a href=&#34;https://gist.github.com/thomwolf/ac7a7da6b1888c2eeac8ac8b9b05d3d3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this link&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If you have GPU bottleneck and decide to go with &lt;code&gt;torch.nn.DataParallel&lt;/code&gt;, there is a catch regarding the batch size.
&lt;ul&gt;
&lt;li&gt;Look at the thread below for more. &lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;I trained a model on 1 GPU and then using &lt;a href=&#34;https://twitter.com/PyTorch?ref_src=twsrc%5Etfw&#34;&gt;@PyTorch&lt;/a&gt; DataParallel on 2 GPUs. Even though I fixed the seed, I got 2 different training plots. &lt;br&gt;&lt;br&gt;Turns out, if you use batchsize=n and GPU_count=x, it&amp;#39;s equivalent to having effective_batchsize=n*x.&lt;/p&gt;&amp;mdash; Rahul Vigneswaran (@somethingmyname) &lt;a href=&#34;https://twitter.com/somethingmyname/status/1400042667543654402?ref_src=twsrc%5Etfw&#34;&gt;June 2, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Useful utilities/commands:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;gpustat --watch&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;glances&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cpu&#34;&gt;CPU&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;If you are running multiple experiments but have limited number of cores, use &lt;code&gt;taskset --cpu-list &amp;lt;starting_thread&amp;gt;-&amp;lt;ending thread number&amp;gt; &amp;lt;your_code&amp;gt;.py&lt;/code&gt;. This will make sure your specific runs use only the allotted threads from &lt;code&gt;&amp;lt;starting_thread&amp;gt;&lt;/code&gt;to &lt;code&gt;&amp;lt;ending thread number&amp;gt;&lt;/code&gt; and prevents from constant reallocation of CPU threads as each run fight for the threads. Note that this is helpful only if everyone on the server respects the core allotment.&lt;/li&gt;
&lt;li&gt;More &lt;code&gt;num_workers&lt;/code&gt; doesn&amp;rsquo;t lead to a faster data loader. In fact, in most cases having higher &lt;code&gt;num_workers&lt;/code&gt; will lead to a slower data loader. As far as I know, there is no thumb rule but there does exist a sweet spot that is mostly identified through trial and error.
&lt;ul&gt;
&lt;li&gt;Check 
&lt;a href=&#34;https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this thread&lt;/a&gt; for more.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Useful utilities/commands:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;htop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;glances&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;storage&#34;&gt;Storage&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Make sure you are running (read, log, train) on SSD. HDD causes I/O bottlenecks which are hard to get over even if you sell your soul to satan.
&lt;ul&gt;
&lt;li&gt;Check with this &lt;code&gt;lsblk -o NAME,MOUNTPOINT,MODEL,ROTA,SIZE&lt;/code&gt;. ROTA == 0 means, the drive is an SSD.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Useful utilities/commands:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ncdu&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;df -h&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;general-training&#34;&gt;General Training&lt;/h2&gt;
&lt;h3 id=&#34;loss&#34;&gt;Loss&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If you have implemented a new type of loss, do a overfit test first. Instead of running the experiments on the entire dataset, overfit a single batch. You should be able to get your lower bound of the implemented loss and 100% train accuracy, else something is wrong with the implementation.
&lt;ul&gt;
&lt;li&gt;Check 
&lt;a href=&#34;http://karpathy.github.io/2019/04/25/recipe/#:~:text=overfit%20one%20batch.%20Overfit%20a%20single%20batch,we%20cannot%20continue%20to%20the%20next%20stage&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Karpathy&amp;rsquo;s blogpost&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nan&lt;/code&gt; related issues:
&lt;ul&gt;
&lt;li&gt;If you have some custom loss and don&amp;rsquo;t know where the &lt;code&gt;nan&lt;/code&gt; is coming from, use 
&lt;a href=&#34;https://pytorch.org/docs/master/autograd.html#anomaly-detection&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyTorch&amp;rsquo;s anamoly detection feature&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Ways to tackle &lt;code&gt;nan&lt;/code&gt; and related issues: 
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/XlYD8jn1ayE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;datasetdataloader&#34;&gt;Dataset/Dataloader&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If you want to know whether that idea that&amp;rsquo;s keeping you awake at night works but ImageNet takes too much time, then check these datasets:
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.kaggle.com/c/tiny-imagenet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tiny ImageNet&lt;/a&gt; : 200 class version of ImageNet&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/yaoyao-liu/mini-imagenet-tools&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mini ImageNet&lt;/a&gt; : 100 class version of ImageNet
&lt;ul&gt;
&lt;li&gt;Note that the above version is for few-shot learning. You can convert it into normal classification using this - &lt;insert link here&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/fastai/imagenette&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Imagenette&lt;/a&gt; : Easier 10 class version of ImageNet
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/fastai/imagenette/tree/master/noisy_labels&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Noisy Imagenette&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/fastai/imagenette#imagewoof&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Imagewoof&lt;/a&gt;: Relatively hard version of Imagenette
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/fastai/imagenette/tree/master/noisy_labels&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Noisy Imagewoof&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/fastai/imagenette#image%E7%BD%91&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Imagewang&lt;/a&gt;: Semi-supervised version which combines both Imagenette and Imagewoof&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;misc&#34;&gt;Misc&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Implement resume functionality ASAP. Trust me, this will prevent crying yourself to sleep at night.
&lt;ul&gt;
&lt;li&gt;If you are using wandb, then you can even resume the logging. Feels like magic. Check the thread below for more. &lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Coming from the world of CIFARs, I have never bothered to implement a resume function in my code. The Big boi datasets finally forced me to write a resume function today. I know exactly how it works but it still feels like magic to resume a large run after it crashes! &lt;a href=&#34;https://t.co/i6uInpIpXx&#34;&gt;pic.twitter.com/i6uInpIpXx&lt;/a&gt;&lt;/p&gt;&amp;mdash; Rahul Vigneswaran (@somethingmyname) &lt;a href=&#34;https://twitter.com/somethingmyname/status/1400237720413171713?ref_src=twsrc%5Etfw&#34;&gt;June 2, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If you come from the happy land of CIFARs and MNISTs like me, don&amp;rsquo;t stare at the runs. It will take days to weeks. Get a hobby or it&amp;rsquo;s finally time to open that &amp;ldquo;Interesting Papers&amp;rdquo; folder.&lt;/li&gt;
&lt;li&gt;As a final note, make sure to avoid everything in the thread below by Karpathy. &lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;most common neural net mistakes: 1) you didn&amp;#39;t try to overfit a single batch first. 2) you forgot to toggle train/eval mode for the net. 3) you forgot to .zero_grad() (in pytorch) before .backward(). 4) you passed softmaxed outputs to a loss that expects raw logits. ; others? :)&lt;/p&gt;&amp;mdash; Andrej Karpathy (@karpathy) &lt;a href=&#34;https://twitter.com/karpathy/status/1013244313327681536?ref_src=twsrc%5Etfw&#34;&gt;July 1, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Deeper Look at the Hessian Eigen spectrum of Deep Neural Networks and its Applications to Regularization</title>
      <link>/publication/layer-hessian-regularizer/</link>
      <pubDate>Wed, 19 Aug 2020 18:48:43 +0530</pubDate>
      <guid>/publication/layer-hessian-regularizer/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Incremental Loss Landscape</title>
      <link>/project/incremental-loss-landscape/</link>
      <pubDate>Wed, 19 Aug 2020 18:14:06 +0530</pubDate>
      <guid>/project/incremental-loss-landscape/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;The theoretical literature on continual learning is minimal, and in this work, we try to fix the same. Worked on understanding how catastrophic forgetting translates to loss landscape and how it can pave the way for more theoretically grounded continual learning methods.&lt;/li&gt;
&lt;li&gt;Worked on understanding how regularization based catastrophic forgetting mitigation techniques behave in loss landscapes and why some methods are more successful in achieving the same than others. Analyzed whether tools like, to name a few - Hessian&amp;rsquo;s Eigen Spectrum, fluctuation-dissipation, intrinsic dimensionality can aid in understanding continual learning better.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Advisor :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.iith.ac.in/~vineethnb/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Vineeth N Balasubramanian&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Layerwise Hessian Analysis</title>
      <link>/project/layerwise-hessian-analysis/</link>
      <pubDate>Sun, 19 Jan 2020 18:04:22 +0530</pubDate>
      <guid>/project/layerwise-hessian-analysis/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Recent works&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; have demonstrated a bulk and outlier trend in their Hessian&amp;rsquo;s Eigen Spectrum. In this work, we have discovered a similar trend in the layer-wise spectrum, too, which indicates an implicit similarity between the overall loss landscape and layer-wise loss landscape, which is a community first.&lt;/li&gt;
&lt;li&gt;We leverage this observation and formulate a regularizer that forces the optimizer to converge to a minima of better generalization properties. Further, through this analysis, we have substantiated that studying the layer-wise loss landscape is worth the community&amp;rsquo;s efforts.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Work accepted at &lt;strong&gt;AAAI&lt;/strong&gt; 2021.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Advisor :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.iith.ac.in/~vineethnb/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Vineeth N Balasubramanian&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;
&lt;a href=&#34;https://arxiv.org/abs/1901.08244&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Measurements of Three-Level Hierarchical Structure in the Outliers in the Spectrum of Deepnet Hessians&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;
&lt;a href=&#34;https://arxiv.org/abs/1706.04454&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Empirical Analysis of the Hessian of Over-Parametrized Neural Networks&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Dynamic Mode Decomposition based feature for Image Classification</title>
      <link>/publication/dmd-based-feature-for-image-classification/</link>
      <pubDate>Tue, 29 Oct 2019 00:31:22 +0530</pubDate>
      <guid>/publication/dmd-based-feature-for-image-classification/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning With Limited Labeled Data</title>
      <link>/project/learning-with-limited-labeled-data/</link>
      <pubDate>Wed, 19 Jun 2019 18:19:59 +0530</pubDate>
      <guid>/project/learning-with-limited-labeled-data/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Worked on understanding the existing techniques used for learning with limited labeled data and explored non-conventional techniques for efficiently learning a distribution with limited-resource.&lt;/li&gt;
&lt;li&gt;Used Dynamic Mode Decomposition (DMD) to extract the dominant features of images for classifying with limited labeled data.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Accepted for an oral presentation at &lt;strong&gt;TENCON&amp;rsquo;19&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Advisors :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://scholar.google.co.in/citations?user=R_zpXOkAAAAJ%5c&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Soman KP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://scholar.google.co.in/citations?user=-ztk7jMAAAAJ%5c&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mr Sachin Kumar S&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Data Drive Computing for Elasticity via Chebyshev Approximation</title>
      <link>/publication/data-drive-computing-for-elasticity-via-chebyshev-approximation/</link>
      <pubDate>Tue, 23 Apr 2019 00:49:15 +0530</pubDate>
      <guid>/publication/data-drive-computing-for-elasticity-via-chebyshev-approximation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Shape Optimization using DMD and POD</title>
      <link>/project/shape-optimization/</link>
      <pubDate>Fri, 19 Apr 2019 17:51:56 +0530</pubDate>
      <guid>/project/shape-optimization/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Explored the idea of Data-driven shape optimization, especially in ship hulls. Used Proper Orthogonal Decomposition based model order reduction approach and Dynamic Mode Decomposition (DMD) to reduce the time of turbulent flow simulation involved.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Advisors :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://scholar.google.co.in/citations?user=R_zpXOkAAAAJ%5c&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Soman KP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://scholar.google.co.in/citations?user=2selpAEAAAAJ%5c&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Gopalakrishnan EA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Compendium on Network and Host Based Intrusion Detection Systems</title>
      <link>/publication/a-compendium-on-network-and-host-based-intrusion-detection-systems/</link>
      <pubDate>Sat, 06 Apr 2019 01:15:09 +0530</pubDate>
      <guid>/publication/a-compendium-on-network-and-host-based-intrusion-detection-systems/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Trace metal analysis of Pre-flood and Post-flood drinking water in Kerala</title>
      <link>/project/trace-metal/</link>
      <pubDate>Wed, 19 Dec 2018 18:16:58 +0530</pubDate>
      <guid>/project/trace-metal/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Conducted a detailed study on various contents of the water samples, especially trace metals, which were collected Pre and post to a Flood in the state of Kerala.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Advisor :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://scholar.google.co.in/citations?user=R_zpXOkAAAAJ%5c&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ms Geena Prasad&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Intrusion Detection Systems</title>
      <link>/project/intrusion-detection-systems/</link>
      <pubDate>Wed, 29 Aug 2018 02:26:30 +0530</pubDate>
      <guid>/project/intrusion-detection-systems/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Implemented and Contrasted Deep and Shallow Neural Nets in the Cybersecurity use case of Intrusion Detection Systems (IDS) while studying the various SOTAs of Host and Network-based Intrusion Detection Systems (IDS).&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Work accepted at a &lt;strong&gt;SCOPUS&lt;/strong&gt; indexed conference held at IISC Banglore.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Advisors :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://scholar.google.co.in/citations?user=R_zpXOkAAAAJ%5c&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Soman KP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://scholar.google.com/citations?user=e233m6MAAAAJ%5c&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Prabaharan Poornachandran&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Evaluating Shallow and Deep Neural Networks for Network Intrusion Detection Systems in Cyber Security</title>
      <link>/publication/evaluating-shallow-and-deep-neural-networks-for-network-intrusion-detection-systems-in-cyber-security/</link>
      <pubDate>Tue, 10 Jul 2018 01:21:44 +0530</pubDate>
      <guid>/publication/evaluating-shallow-and-deep-neural-networks-for-network-intrusion-detection-systems-in-cyber-security/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PatchUp: A Regularization Technique for Convolutional Neural Networks</title>
      <link>/implementations/patch-up/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/implementations/patch-up/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
