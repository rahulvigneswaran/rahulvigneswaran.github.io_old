[{"authors":["admin"],"categories":null,"content":"I am currently working with Makarand Tapaswi from Wadhwani AI and Marc Law from Nvidia Toronto AI Lab on problems related to Long-tail distribution in an image classification setting.\nI am also a research Intern at IIT Hyderabad\u0026lsquo;s Machine Learning and Vision Lab advised by Dr Vineeth N Balasubramanian where I work on understanding machine learning models that can learn incrementally.\nPrior to that I worked remotely with Piero Molino from Hazy Research, Stanford on Natural Language Generation.\n  --      For a more consolidated version of this website, take a look at my CV\n","date":1597843123,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1597843123,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am currently working with Makarand Tapaswi from Wadhwani AI and Marc Law from Nvidia Toronto AI Lab on problems related to Long-tail distribution in an image classification setting.\nI am also a research Intern at IIT Hyderabad\u0026lsquo;s Machine Learning and Vision Lab advised by Dr Vineeth N Balasubramanian where I work on understanding machine learning models that can learn incrementally.","tags":null,"title":"Rahul Vigneswaran","type":"authors"},{"authors":["Adepu Ravi Shankar","Yash Khasbage","Rahul Vigneswaran","Vineeth N Balasubramanian"],"categories":[],"content":"","date":1597843123,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597843123,"objectID":"25d16180c83d90d8480b474f4ebffbfd","permalink":"/publication/layer-hessian-regularizer/","publishdate":"2020-08-19T18:48:43+05:30","relpermalink":"/publication/layer-hessian-regularizer/","section":"publication","summary":"Loss landscape analysis is extremely useful for a deeper understanding of the generalization ability of deep neural network models. In this work, we propose a layerwise loss landscape analysis where the loss surface at every layer is studied independently and also on how each correlates to the overall loss surface. We study the layerwise loss landscape by studying the eigenspectra of the Hessian at each layer. In particular, our results show that the layerwise Hessian geometry is largely similar to the entire Hessian. We also report an interesting phenomenon where the Hessian eigenspectrum of middle layers of the deep neural network are observed to most similar to the overall Hessian eigenspectrum. We also show that the maximum eigenvalue and the trace of the Hessian (both full network and layerwise) reduce as training of the network progresses. We leverage on these observations to propose a new regularizer based on the trace of the layerwise Hessian. Penalizing the trace of the Hessian at every layer indirectly forces Stochastic Gradient Descent to converge to flatter minima, which are shown to have better generalization performance. In particular, we show that such a layerwise regularizer can be leveraged to penalize the middlemost layers alone, which yields promising results. Our empirical studies on well-known deep nets across datasets support the claims of this work.","tags":[],"title":"A Deeper Look at the Hessian Eigen spectrum of Deep Neural Networks and its Applications to Regularization","type":"publication"},{"authors":["Rahul Vigneswaran"],"categories":[],"content":" The theoretical literature on continual learning is minimal, and in this work, we try to fix the same. Worked on understanding how catastrophic forgetting translates to loss landscape and how understanding it can pave the way for more theoretically grounded continual learning methods. Worked on understanding how regularization based catastrophic forgetting mitigation techniques behave in loss landscapes and why some methods are more successful in achieving the same than others. Analyzed whether tools like, to name a few - PAC-Bayesian, Hessian\u0026rsquo;s Eigen Spectrum, fluctuation-dissipation, intrinsic dimensionality can aid in understanding continual learning better.  Advisor :\n  Dr Vineeth N Balasubramanian  ","date":1597841046,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597841046,"objectID":"c9fa8adf05a4e81b3d908de3b1840f5c","permalink":"/project/incremental-loss-landscape/","publishdate":"2020-08-19T18:14:06+05:30","relpermalink":"/project/incremental-loss-landscape/","section":"project","summary":"Explores the continual/incremental learning setting in Deep learning from the perspective of loss landscapes.","tags":["research"],"title":"Incremental Loss Landscape","type":"project"},{"authors":["Rahul Vigneswaran"],"categories":[],"content":" Recent works1 2 have demonstrated a bulk and outlier trend in their Hessian\u0026rsquo;s Eigen Spectrum. In this work, we have discovered a similar trend in the layer-wise spectrum, too, which indicates an implicit similarity between the overall loss landscape and layer-wise loss landscape, which is a community first. We leverage this observation and formulate a regularizer that forces the optimizer to converge to a minima of better generalization properties. Further, through this analysis, we have substantiated that studying the layer-wise loss landscape is worth the community\u0026rsquo;s efforts.   Work under review at a Top-Tier Conference.\n Advisor :\n  Dr Vineeth N Balasubramanian     Measurements of Three-Level Hierarchical Structure in the Outliers in the Spectrum of Deepnet Hessians \u0026#x21a9;\u0026#xfe0e;\n  Empirical Analysis of the Hessian of Over-Parametrized Neural Networks \u0026#x21a9;\u0026#xfe0e;\n   ","date":1579437262,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579437262,"objectID":"3ecfd0061f8a8a726332d428331fbeb9","permalink":"/project/layerwise-hessian-analysis/","publishdate":"2020-01-19T18:04:22+05:30","relpermalink":"/project/layerwise-hessian-analysis/","section":"project","summary":"Understanding and leveraging the properties of layerwise losslandscape in conjunction with the overall loss landscape.","tags":["research"],"title":"Layerwise Hessian Analysis","type":"project"},{"authors":["Rahul Vigneswaran","Sachin-Kumar S","Neethu Mohan","Soman KP"],"categories":[],"content":"","date":1572289282,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572289282,"objectID":"bb99370102bac471d5c0e5d239d02bae","permalink":"/publication/dmd-based-feature-for-image-classification/","publishdate":"2020-03-29T00:31:22+05:30","relpermalink":"/publication/dmd-based-feature-for-image-classification/","section":"publication","summary":"Irrespective of the fact that Machine learning has produced groundbreaking results, it demands an enormous amount of data in order to perform so. Even though data production has been in its all-time high, almost all the data is unlabelled, hence making them unsuitable for training the algorithms. This paper proposes a novel method of extracting the features using Dynamic Mode Decomposition (DMD). The experiment is performed using data samples from Imagenet. The learning is done using SVM-linear, SVM-RBF, Random Kitchen Sink approach (RKS). The results have shown that DMD features with RKS give competing results.","tags":["limited-data","dmd"],"title":"Dynamic Mode Decomposition based feature for Image Classification","type":"publication"},{"authors":["Rahul Vigneswaran"],"categories":[],"content":" Worked on understanding the existing techniques used for learning with limited labeled data and explored non-conventional techniques for efficiently learning a distribution with limited-resource. Used Dynamic Mode Decomposition (DMD) to extract the dominant features of images for classifying with limited labeled data.   Accepted for an oral presentation at TENCON\u0026rsquo;19.\n Advisors :\n  Dr Soman KP  Mr Sachin Kumar S  ","date":1560948599,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560948599,"objectID":"e5827769f723e2a72cb24e163a228de3","permalink":"/project/learning-with-limited-labeled-data/","publishdate":"2019-06-19T18:19:59+05:30","relpermalink":"/project/learning-with-limited-labeled-data/","section":"project","summary":"Using the concept of Dynamic Mode Decomposition from the field of Fluid Dynamics in a classification setting with limited labeled data.","tags":["academic"],"title":"Learning With Limited Labeled Data","type":"project"},{"authors":["Rahul Vigneswaran","Neethu Mohan","Soman KP"],"categories":[],"content":"","date":1555960755,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555960755,"objectID":"eae6444277c5bae38720240c5ef5d59c","permalink":"/publication/data-drive-computing-for-elasticity-via-chebyshev-approximation/","publishdate":"2020-03-29T00:49:15+05:30","relpermalink":"/publication/data-drive-computing-for-elasticity-via-chebyshev-approximation/","section":"publication","summary":"This paper proposes a data-driven approach for computing elasticity by means of a non-parametric regression approach rather than an optimization approach. The Chebyshev approximation is utilized for tackling the material data-sets non-linearity of the elasticity. Also, additional efforts have been taken to compare the results with several other state-of-the-art methodologies.","tags":["chebfun","data-driven","elasticity","mechanical"],"title":"Data Drive Computing for Elasticity via Chebyshev Approximation","type":"publication"},{"authors":["Rahul Vigneswaran"],"categories":[],"content":" Explored the idea of Data-driven shape optimization, especially in ship hulls. Used Proper Orthogonal Decomposition based model order reduction approach and Dynamic Mode Decomposition (DMD) to reduce the time of turbulent flow simulation involved.  Advisors :\n  Dr Soman KP  Dr Gopalakrishnan EA  ","date":1555676516,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555676516,"objectID":"fe3a5f37189cae60d62482f1dcafeaef","permalink":"/project/shape-optimization/","publishdate":"2019-04-19T17:51:56+05:30","relpermalink":"/project/shape-optimization/","section":"project","summary":"Exploring ways to reduce the time of turbulent flow simulation in shape optimization of ship hulls.","tags":["research"],"title":"Shape Optimization using DMD and POD","type":"project"},{"authors":["Rahul Vigneswaran","Prabaharan Poornachandran","Soman KP"],"categories":[],"content":"","date":1554493509,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554493509,"objectID":"9dbc95faac51a6609a5f304d5d91c21a","permalink":"/publication/a-compendium-on-network-and-host-based-intrusion-detection-systems/","publishdate":"2020-03-29T01:15:09+05:30","relpermalink":"/publication/a-compendium-on-network-and-host-based-intrusion-detection-systems/","section":"publication","summary":"The techniques of deep learning have become the state of the art methodology for executing complicated tasks from various domains of computer vision, natural language processing, and several other areas. Due to its rapid development and promising benchmarks in those fields, researchers started experimenting with this technique to perform in the area of, especially in intrusion detection related tasks. Deep learning is a subset and a natural extension of classical Machine learning and an evolved model of neural networks. This paper contemplates and discusses all the methodologies related to the leading edge Deep learning and Neural network models purposing to the arena of Intrusion Detection Systems.","tags":["cyber-security","intrusion-detection-system"],"title":"A Compendium on Network and Host Based Intrusion Detection Systems","type":"publication"},{"authors":["Rahul Vigneswaran"],"categories":[],"content":" Conducted a detailed study on various contents of the water samples, especially trace metals, which were collected Pre and post to a Flood in the state of Kerala.  Advisor :\n  Ms Geena Prasad  ","date":1545223618,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545223618,"objectID":"3e5a70dc443e545239ab1f666bce69c7","permalink":"/project/trace-metal/","publishdate":"2018-12-19T18:16:58+05:30","relpermalink":"/project/trace-metal/","section":"project","summary":"Analysing the trace metal content in pre and post flood conditions.","tags":["academic"],"title":"Trace metal analysis of Pre-flood and Post-flood drinking water in Kerala","type":"project"},{"authors":["Rahul Vigneswaran"],"categories":[],"content":" Implemented and Contrasted Deep and Shallow Neural Nets in the Cybersecurity use case of Intrusion Detection Systems (IDS) while studying the various SOTAs of Host and Network-based Intrusion Detection Systems (IDS).   Work accepted at a SCOPUS indexed conference held at IISC Banglore.\n Advisors :\n  Dr Soman KP  Dr Prabaharan Poornachandran  ","date":1535489790,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535489790,"objectID":"b36e0d5efd1183728d79d709482624c0","permalink":"/project/intrusion-detection-systems/","publishdate":"2018-08-29T02:26:30+05:30","relpermalink":"/project/intrusion-detection-systems/","section":"project","summary":"Understanding the effects of deep and shallow neural networks in Intrusion Detection Systems (IDS).","tags":["research"],"title":"Intrusion Detection Systems","type":"project"},{"authors":["Rahul Vigneswaran","Vinayakumar R","Soman KP","Prabaharan Poornachandran"],"categories":[],"content":"","date":1531165904,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531165904,"objectID":"554f733208902b342894c89bb4102198","permalink":"/publication/evaluating-shallow-and-deep-neural-networks-for-network-intrusion-detection-systems-in-cyber-security/","publishdate":"2020-03-29T01:21:44+05:30","relpermalink":"/publication/evaluating-shallow-and-deep-neural-networks-for-network-intrusion-detection-systems-in-cyber-security/","section":"publication","summary":"Intrusion detection system (IDS) has become an essential layer in all the latest ICT system due to an urge towards cyber safety in the day-to-day world. Reasons including uncertainty in ﬁnding the types of attacks and increased the complexity of advanced cyber attacks, IDS calls for the need of integration of Deep Neural Networks (DNNs). In this paper, DNNs have been utilized to predict the attacks on Network Intrusion Detection System (N-IDS). A DNN with 0.1 rate of learning is applied and is run for 1000 number of epochs and KDDCup-’99’ dataset has been used for training and benchmarking the network. For comparison purposes, the training is done on the same dataset with several other classical machine learning algorithms and DNN of layers ranging from 1 to 5. The results were compared and concluded that a DNN of 3 layers has superior performance over all the other classical machine learning algorithms.","tags":["cyber-security","intrusion-detection-system"],"title":"Evaluating Shallow and Deep Neural Networks for Network Intrusion Detection Systems in Cyber Security","type":"publication"},{"authors":null,"categories":null,"content":"\r[Dec 2020] : Our work titled A Deeper Look at the Hessian Eigenspectrum of Deep Neural Networks and its Applications to Regularization got accepted into AAAI 2021.\n[Oct 2020] : Started working with Makarand Tapaswi from Wadhwani AI on problems related to Long-tail distribution.\n[May 2020] : Started working remotely with Piero Molino from Uber AI, San Francisco, USA.\n[July 2019] : Joined as a Research Intern under Dr Vineeth N Balasubramanian at IIT Hyderabad\u0026lsquo;s Machine Learning and Vision Lab.\n","date":1512066600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512066600,"objectID":"a0812ae5f3c926fea6faf4472cefc8e2","permalink":"/news/","publishdate":"2017-12-01T00:00:00+05:30","relpermalink":"/news/","section":"","summary":"\r\nList of news.\r\n","tags":[],"title":"News","type":"page"}]